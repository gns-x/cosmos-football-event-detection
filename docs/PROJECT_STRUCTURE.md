# Project Structure
## Cosmos Football Video Analysis

This document describes the organized project structure following best practices for machine learning projects.

## ğŸ“ **Root Directory Structure**

```
cosmos-football-event-detection/
â”œâ”€â”€ README.md                           # Main project README
â”œâ”€â”€ Makefile                           # Deployment and automation commands
â”œâ”€â”€ environment.yml                    # Conda environment specification
â”œâ”€â”€ activate_env.sh                    # Environment activation script
â”œâ”€â”€ docs/                              # ğŸ“š All documentation files
â”œâ”€â”€ scripts/                           # ğŸ”§ All executable scripts
â”œâ”€â”€ tests/                             # ğŸ§ª All test files and results
â”œâ”€â”€ 01_data_collection/               # Data collection phase
â”œâ”€â”€ 02_preprocessing/                 # Video preprocessing phase
â”œâ”€â”€ 03_annotation/                    # Manual annotation phase
â”œâ”€â”€ 04_dataset/                       # Dataset preparation phase
â”œâ”€â”€ 05_training/                      # Model training phase
â”œâ”€â”€ 06_evaluation/                    # Model evaluation phase
â””â”€â”€ 07_inference/                     # Model inference phase
```

## ğŸ“š **Documentation (`docs/`)**

All markdown documentation files (except README files) are organized in the `docs/` folder:

```
docs/
â”œâ”€â”€ PROJECT_STRUCTURE.md              # This file
â”œâ”€â”€ AZURE_DEPLOYMENT.md               # Azure A100 VM deployment guide
â”œâ”€â”€ AZURE_READY.md                    # Azure deployment readiness summary
â”œâ”€â”€ ALL_TESTS_FIXED.md                # Test fixes documentation
â”œâ”€â”€ CRITICAL_TEST_RESULTS.md          # Critical test results
â”œâ”€â”€ SFT_DATASET_README.md             # SFT dataset documentation
â”œâ”€â”€ evaluation_report.md              # Evaluation results report
â””â”€â”€ [other documentation files]
```

## ğŸ”§ **Scripts (`scripts/`)**

All executable scripts are organized in the `scripts/` folder:

```
scripts/
â”œâ”€â”€ azure_setup.sh                    # Complete Azure VM setup
â”œâ”€â”€ azure_quick_start.sh              # One-command Azure deployment
â”œâ”€â”€ run_end_to_end_test.py            # Critical pipeline testing
â”œâ”€â”€ test_pipeline.py                  # Alternative testing
â””â”€â”€ download_test_video.py            # Test video download script
```

## ğŸ§ª **Tests (`tests/`)**

All test files and test results are organized in the `tests/` folder:

```
tests/
â”œâ”€â”€ test_ffmpeg_command.sh            # FFmpeg command testing
â”œâ”€â”€ test_inference.py                 # Inference testing
â”œâ”€â”€ test_results/                     # Test execution results
â”‚   â””â”€â”€ test_analysis_result.json
â””â”€â”€ batch_test_results/               # Batch testing results
    â”œâ”€â”€ batch_analysis_results.json
    â”œâ”€â”€ goal_sample_1_processed_analysis.json
    â”œâ”€â”€ penalty_shot_sample_1_processed_analysis.json
    â””â”€â”€ red_card_sample_1_processed_analysis.json
```

## ğŸ¯ **Phase-Based Organization**

The project follows a clear phase-based structure for the machine learning pipeline:

### **Phase 1: Data Collection (`01_data_collection/`)**
```
01_data_collection/
â”œâ”€â”€ download_videos.sh                # Video download script
â”œâ”€â”€ collect_sample_data.py            # Sample data collection
â””â”€â”€ raw_videos/                       # Raw video files
    â”œâ”€â”€ goal/
    â”œâ”€â”€ penalty_shot/
    â”œâ”€â”€ red_card/
    â””â”€â”€ [other classes]
```

### **Phase 2: Preprocessing (`02_preprocessing/`)**
```
02_preprocessing/
â”œâ”€â”€ preprocess.sh                     # Video preprocessing script
â””â”€â”€ processed_videos/                 # Processed video files
    â”œâ”€â”€ goal/
    â”œâ”€â”€ penalty_shot/
    â”œâ”€â”€ red_card/
    â””â”€â”€ [other classes]
```

### **Phase 3: Annotation (`03_annotation/`)**
```
03_annotation/
â”œâ”€â”€ setup_annotation_tool.py         # Annotation tool setup
â”œâ”€â”€ create_ground_truth.py            # Ground truth creation
â”œâ”€â”€ manual_annotation.py              # Manual annotation script
â”œâ”€â”€ annotation_tool/                  # Web-based annotation tool
â””â”€â”€ ground_truth_json/                # Ground truth JSON files
```

### **Phase 4: Dataset (`04_dataset/`)**
```
04_dataset/
â”œâ”€â”€ build_dataset.py                  # Dataset building script
â”œâ”€â”€ build_sft_dataset.py              # SFT dataset building
â”œâ”€â”€ train.jsonl                       # Training dataset
â”œâ”€â”€ validation.jsonl                  # Validation dataset
â””â”€â”€ test.jsonl                        # Test dataset
```

### **Phase 5: Training (`05_training/`)**
```
05_training/
â”œâ”€â”€ azure_training.py                 # Azure-optimized training
â”œâ”€â”€ azure_training_config.toml        # Azure training configuration
â”œâ”€â”€ football_sft.py                   # Football SFT training
â”œâ”€â”€ fine_tune.py                      # Fine-tuning script
â”œâ”€â”€ configs/                          # Training configurations
â”‚   â”œâ”€â”€ azure_deepspeed_config.json
â”‚   â””â”€â”€ deepspeed_config.json
â”œâ”€â”€ checkpoints/                      # Model checkpoints
â””â”€â”€ cosmos-cookbook/                  # NVIDIA Cosmos Cookbook submodule
```

### **Phase 6: Evaluation (`06_evaluation/`)**
```
06_evaluation/
â”œâ”€â”€ evaluate.py                       # Evaluation script
â”œâ”€â”€ generate_predictions.py           # Prediction generation
â”œâ”€â”€ run_evaluation.py                 # Evaluation runner
â”œâ”€â”€ results/                          # Evaluation results
â”œâ”€â”€ metrics/                          # Evaluation metrics
â””â”€â”€ reports/                          # Evaluation reports
```

### **Phase 7: Inference (`07_inference/`)**
```
07_inference/
â”œâ”€â”€ football_inference.py             # Production inference
â”œâ”€â”€ simple_inference.py              # Simplified inference
â”œâ”€â”€ inference.py                     # Basic inference script
â””â”€â”€ requirements.txt                 # Inference dependencies
```

## ğŸš€ **Deployment Commands**

The project includes comprehensive deployment automation:

```bash
# Quick deployment
make deploy

# Step-by-step deployment
make setup          # Setup environment
make install        # Install dependencies
make test          # Run pipeline tests
make train         # Execute fine-tuning
make evaluate      # Run evaluation
make inference     # Test inference
make validate      # Complete validation

# Azure-specific deployment
./scripts/azure_quick_start.sh
```

## ğŸ“Š **File Organization Principles**

### **1. Documentation Separation**
- All `.md` files (except README files) go in `docs/`
- README files stay in their respective directories
- Documentation is centralized and easily accessible

### **2. Script Centralization**
- All executable scripts go in `scripts/`
- Scripts are organized by functionality
- Easy to find and execute

### **3. Test Organization**
- All test files go in `tests/`
- Test results are organized in subdirectories
- Clear separation of test code and results

### **4. Phase-Based Structure**
- Each phase has its own directory
- Clear progression through the pipeline
- Easy to understand the workflow

## ğŸ”§ **Maintenance and Updates**

### **Adding New Documentation**
```bash
# Add new documentation
mv new_documentation.md docs/
```

### **Adding New Scripts**
```bash
# Add new scripts
mv new_script.py scripts/
chmod +x scripts/new_script.py
```

### **Adding New Tests**
```bash
# Add new tests
mv new_test.py tests/
```

### **Updating References**
When moving files, update references in:
- `Makefile`
- Script imports
- Configuration files
- Documentation links

## ğŸ“‹ **Best Practices**

### **1. File Naming**
- Use descriptive names
- Use snake_case for Python files
- Use kebab-case for documentation
- Use UPPERCASE for configuration files

### **2. Directory Structure**
- Keep related files together
- Use clear, descriptive directory names
- Follow the established phase-based structure

### **3. Documentation**
- Keep documentation up to date
- Use consistent formatting
- Include examples and usage instructions

### **4. Scripts**
- Make scripts executable
- Include proper error handling
- Add usage documentation
- Use consistent coding style

## ğŸ¯ **Benefits of This Structure**

1. **Clear Organization**: Easy to find files and understand the project
2. **Scalability**: Easy to add new components and phases
3. **Maintainability**: Clear separation of concerns
4. **Collaboration**: Team members can easily navigate the project
5. **Deployment**: Automated deployment with clear commands
6. **Testing**: Organized test structure with clear results
7. **Documentation**: Centralized and accessible documentation

---

**This project structure follows industry best practices for machine learning projects and provides a clear, organized, and maintainable codebase.**

